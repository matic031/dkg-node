import type {
  AIMessageChunk,
  MessageFieldWithRole,
} from "@langchain/core/messages";
import type {
  BaseFunctionCallOptions,
  ToolDefinition,
} from "@langchain/core/language_models/base";
import type { CallToolResult } from "@modelcontextprotocol/sdk/types.js";

export type { ToolDefinition };
export type ToolInfo = {
  name: string;
  title?: string;
  description?: string;
  args?: ToolDefinition["function"]["parameters"];
};
export type ToolCallsMap = Record<
  string,
  {
    input?: unknown;
    output?: unknown;
    status: "init" | "loading" | "success" | "error" | "cancelled";
    error?: string;
  }
>;

export type CompletionRequest = {
  messages: ChatMessage[];
  tools?: ToolDefinition[];
  options?: BaseFunctionCallOptions;
};

export type ChatMessage = MessageFieldWithRole & {
  content: AIMessageChunk["content"];
  tool_calls?: AIMessageChunk["tool_calls"];
};

export type ToolCall = NonNullable<AIMessageChunk["tool_calls"]>[number];
export type ToolCallResultContent = CallToolResult["content"];

export const toContents = (content: ChatMessage["content"]) =>
  typeof content === "string" ? [{ type: "text", text: content }] : content;

export type ChatMessageContents = ReturnType<typeof toContents>;

export enum LLMProvider {
  OpenAI = "openai",
  Groq = "groq",
  Anthropic = "anthropic",
  GoogleGenAI = "google-genai",
  MistralAI = "mistralai",
  XAI = "xai",
  SelfHosted = "self-hosted",
}

export const isValidLLMProvider = (
  llmProvider: string,
): llmProvider is LLMProvider =>
  Object.values(LLMProvider).includes(llmProvider as any);

export const getLLMProviderApiKeyEnvName = (llmProvider: LLMProvider) => {
  switch (llmProvider) {
    case LLMProvider.OpenAI:
      return "OPENAI_API_KEY";
    case LLMProvider.Groq:
      return "GROQ_API_KEY";
    case LLMProvider.Anthropic:
      return "ANTHROPIC_API_KEY";
    case LLMProvider.GoogleGenAI:
      return "GOOGLE_API_KEY";
    case LLMProvider.MistralAI:
      return "MISTRAL_API_KEY";
    case LLMProvider.XAI:
      return "XAI_API_KEY";
    case LLMProvider.SelfHosted:
      return "LLM_URL";
    default:
      throw new Error(`Unsupported LLM provider: ${llmProvider}`);
  }
};

const llmProviderFromEnv = async () => {
  const provider = process.env.LLM_PROVIDER || LLMProvider.OpenAI;
  if (!isValidLLMProvider(provider)) {
    throw new Error(`Unsupported LLM provider: ${provider}`);
  }
  const model = process.env.LLM_MODEL || "gpt-4o-mini";
  const temperature = Number(process.env.LLM_TEMPERATURE || "0");
  if (isNaN(temperature)) {
    throw new Error(`Invalid LLM temperature: ${temperature}`);
  }

  switch (provider) {
    case LLMProvider.Groq:
      return import("@langchain/groq").then(
        ({ ChatGroq }) => new ChatGroq({ model, temperature }),
      );
    case LLMProvider.Anthropic:
      return import("@langchain/anthropic").then(
        ({ ChatAnthropic }) => new ChatAnthropic({ model, temperature }),
      );
    case LLMProvider.GoogleGenAI:
      return import("@langchain/google-genai").then(
        ({ ChatGoogleGenerativeAI }) =>
          new ChatGoogleGenerativeAI({ model, temperature }),
      );
    case LLMProvider.MistralAI:
      return import("@langchain/mistralai").then(
        ({ ChatMistralAI }) => new ChatMistralAI({ model, temperature }),
      );
    case LLMProvider.XAI:
      return import("@langchain/xai").then(
        ({ ChatXAI }) => new ChatXAI({ model, temperature }),
      );
    case LLMProvider.SelfHosted:
      return import("@langchain/openai").then(
        ({ ChatOpenAI }) =>
          new ChatOpenAI({
            model,
            temperature,
            configuration: {
              baseURL:
                (process.env.LLM_URL || "http://localhost:11434") + "/v1",
              apiKey: "_",
            },
          }),
      );
    case LLMProvider.OpenAI:
    default:
      return import("@langchain/openai").then(
        ({ ChatOpenAI }) => new ChatOpenAI({ model, temperature }),
      );
  }
};

export const llmProvider = async () => {
  const s = globalThis as typeof globalThis & {
    llmProvider?: Awaited<ReturnType<typeof llmProviderFromEnv>>;
  };

  if (!s.llmProvider) s.llmProvider = await llmProviderFromEnv();
  return s.llmProvider;
};

export const processCompletionRequest = async (req: Request) => {
  const body: CompletionRequest = await req.json();
  const provider = await llmProvider();
  const res = await provider.invoke(
    [
      {
        role: "system",
        content: process.env.LLM_SYSTEM_PROMPT || DEFAULT_SYSTEM_PROMPT,
      },
      ...body.messages,
    ],
    {
      ...body.options,
      tools: body.tools,
    },
  );
  return Response.json({
    role: "assistant",
    content: res.content,
    tool_calls: res.tool_calls,
  } satisfies ChatMessage);
};

export const makeCompletionRequest = async (
  req: CompletionRequest,
  opts?: {
    fetch?: typeof fetch;
    bearerToken?: string;
  },
) =>
  (opts?.fetch || fetch)(new URL(process.env.EXPO_PUBLIC_APP_URL + "/llm"), {
    body: JSON.stringify(req),
    headers: {
      Authorization: `Bearer ${opts?.bearerToken}`,
      // Itentionally omit the 'Content-Type' header
      // Because it breaks the production build
      //
      // "Content-Type": "application/json",
    },
    method: "POST",
  }).then((r) => {
    if (r.status === 200) return r.json() as Promise<ChatMessage>;
    if (r.status === 401) throw new Error("Unauthorized");
    if (r.status === 403) throw new Error("Forbidden");
    throw new Error(`Unexpected status code: ${r.status}`);
  });

export const DEFAULT_SYSTEM_PROMPT = `
You are a compassionate and knowledgeable Health Assistant powered by the OriginTrail Decentralized Knowledge Graph (DKG). You combine medical expertise with verifiable, evidence-based information to help users make informed health decisions.

## Your Role: Like a Caring Doctor
You act as a trusted health advisor who:
- Provides evidence-based health information with empathy and care
- Uses clear, understandable language while being medically accurate
- Always emphasizes consulting healthcare professionals for personal medical advice
- Makes complex medical concepts accessible and understandable
- Maintains a warm, supportive, and professional tone

## Core Capabilities
- **Health Analysis**: Evaluate health claims using current medical evidence
- **Evidence-Based Guidance**: Provide information backed by peer-reviewed research
- **DKG Integration**: Publish verified health information for long-term accessibility
- **Premium Insights**: Offer enhanced analysis with expert commentary and citations

## Medical Communication Style
- **Empathetic**: "I understand you're looking for ways to improve your gym performance..."
- **Evidence-Focused**: "Based on current research studies..."
- **Cautious**: "While this shows promise, individual results may vary..."
- **Actionable**: "Consider consulting a healthcare provider before starting..."
- **Educational**: Explain medical concepts clearly without overwhelming

## Privacy & Ethics (CRITICAL)
- Health information is sensitive - ALWAYS default to private publishing
- Never provide personalized medical diagnoses or treatment plans
- Always recommend consulting qualified healthcare professionals
- Be transparent about limitations of AI-based health information

## Health Claims Analysis Protocol
When users ask about health claims, medical topics, or wellness questions:

### Initial Response Structure:
1. **Acknowledge Concern**: Show empathy and understanding
2. **Provide Evidence-Based Answer**: Clear, concise assessment
3. **Explain Reasoning**: Reference studies, mechanisms, limitations
4. **Give Practical Advice**: Actionable recommendations
5. **Offer Verification**: Publish as DKG Community Note for permanence
6. **Mention Premium Access**: Enhanced analysis available for 1 TRAC

### Publishing Health Information:
- Always offer to publish analyses as Community Notes for verifiability
- Explain that this creates permanent, tamper-proof health records
- Mention premium access provides expert-reviewed enhancements

## Example Doctor-Patient Interactions

**Patient Concern â†’ Caring Response:**
Patient: "Does ashwagandha help with gym performance?"
You: "I understand you're interested in natural ways to enhance your workout results. Let me review the current evidence on ashwagandha for exercise performance..."

**Evidence-Based Analysis:**
"...Several studies show ashwagandha may help reduce exercise-induced stress and slightly improve strength, but results are modest and more research is needed. Individual responses vary significantly..."

**Cautious Recommendations:**
"...Before starting any supplement, I recommend discussing this with your healthcare provider, especially if you have any medical conditions or take medications..."

**DKG Integration:**
"...If you'd like this analysis preserved as a verifiable Community Note on the OriginTrail DKG, I can publish it for you. Premium access provides enhanced analysis with expert commentary and medical citations."

## Medical Disclaimer Integration
Always include appropriate medical disclaimers and encourage professional consultation.
`.trim();
